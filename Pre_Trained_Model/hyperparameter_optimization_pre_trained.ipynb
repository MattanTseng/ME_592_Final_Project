{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47cba282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from skimage import io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange, repeat\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, '../utils/')\n",
    "from dataset import ChestImage64\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "from torch.utils.data import random_split, DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c69150c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_path = \"../64pxImages/train_labels_64p.csv\"\n",
    "# root_path = '../64pxImages'\n",
    "\n",
    "csv_path = \"../Data/256pxImages/train_labels_256p.csv\" #I had to change \\ to / for this but disregared if it is not an issue for you\n",
    "root_path = \"../Data/256pxImages/\"\n",
    "\n",
    "\n",
    "default_transform = ViT_B_16_Weights.IMAGENET1K_SWAG_LINEAR_V1.transforms\n",
    "\n",
    "\n",
    "data_transform = Compose([\n",
    "    Resize((64, 64)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b8bdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61266, 19)\n",
      "Frontal/patient00004_study1_Frontal.png\n",
      "label_test:  [1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([256, 256])\n"
     ]
    }
   ],
   "source": [
    "myCSV = pd.read_csv(csv_path)\n",
    "myCSV['EncodedLabels'] = ''\n",
    "print(myCSV.shape)\n",
    "\n",
    "\n",
    "# for i in range(4, myCSV.shape[1]-1):\n",
    "#     myCSV['EncodedLabels'] = myCSV['EncodedLabels'].astype(str) + myCSV.iloc[:, i].astype(str) \n",
    "#     if i < myCSV.shape[1]-2:\n",
    "#         myCSV['EncodedLabels'] = myCSV['EncodedLabels'].astype(str) + \",\" \n",
    "\n",
    "for i in range(4, myCSV.shape[1]-1):\n",
    "    myCSV['EncodedLabels'] = myCSV['EncodedLabels'].astype(str) + myCSV.iloc[:, i].astype(str) \n",
    "    if i < myCSV.shape[1]-2:\n",
    "        myCSV['EncodedLabels'] = myCSV['EncodedLabels'].astype(str) + \",\" \n",
    "\n",
    "\n",
    "\n",
    "# myCSV['EncodedLabels'] = myCSV['EncodedLabels'].astype(str) + \"]\"\n",
    "\n",
    "\n",
    "# We can use the encodedlabels column as our labels for our data\n",
    "\n",
    "# since we are not useing cross attention, pull out only the frontal images. \n",
    "frontalCSV = myCSV[myCSV['Frontal/Lateral'].str.contains(\"Frontal\")]\n",
    "frontalCSV.head()\n",
    "\n",
    "filename = frontalCSV.iloc[1, 0]\n",
    "print(filename)\n",
    "\n",
    "label_test = frontalCSV['EncodedLabels'].iloc[0]\n",
    "\n",
    "test_path = os.path.join(root_path, filename)\n",
    "\n",
    "\n",
    "label_test = [int(x) for x in label_test.split(\",\")]\n",
    "\n",
    "print(\"label_test: \", label_test)\n",
    "\n",
    "image = io.imread(test_path)\n",
    "print(type(image))\n",
    "image = torch.tensor(image)\n",
    "print(image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "605e56bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>256path</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Study</th>\n",
       "      <th>Frontal/Lateral</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>EncodedLabels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frontal/patient00002_study1_Frontal.png</td>\n",
       "      <td>patient00002</td>\n",
       "      <td>study1</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,1,1,1,0,1,1,1,0,0,1,1,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lateral/patient00002_study1_Lateral.png</td>\n",
       "      <td>patient00002</td>\n",
       "      <td>study1</td>\n",
       "      <td>Lateral</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,1,1,1,0,1,1,1,0,0,1,1,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frontal/patient00004_study1_Frontal.png</td>\n",
       "      <td>patient00004</td>\n",
       "      <td>study1</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lateral/patient00004_study1_Lateral.png</td>\n",
       "      <td>patient00004</td>\n",
       "      <td>study1</td>\n",
       "      <td>Lateral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frontal/patient00005_study1_Frontal.png</td>\n",
       "      <td>patient00005</td>\n",
       "      <td>study1</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,1,0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   256path       Patient   Study  \\\n",
       "0  Frontal/patient00002_study1_Frontal.png  patient00002  study1   \n",
       "1  Lateral/patient00002_study1_Lateral.png  patient00002  study1   \n",
       "2  Frontal/patient00004_study1_Frontal.png  patient00004  study1   \n",
       "3  Lateral/patient00004_study1_Lateral.png  patient00004  study1   \n",
       "4  Frontal/patient00005_study1_Frontal.png  patient00005  study1   \n",
       "\n",
       "  Frontal/Lateral  Enlarged Cardiomediastinum  Cardiomegaly  Lung Opacity  \\\n",
       "0         Frontal                           1             1             1   \n",
       "1         Lateral                           1             1             1   \n",
       "2         Frontal                           0             0             0   \n",
       "3         Lateral                           0             0             0   \n",
       "4         Frontal                           0             0             0   \n",
       "\n",
       "   Lung Lesion  Edema  Consolidation  Pneumonia  Atelectasis  Pneumothorax  \\\n",
       "0            1      0              1          1            1             0   \n",
       "1            1      0              1          1            1             0   \n",
       "2            0      0              0          0            0             0   \n",
       "3            0      0              0          0            0             0   \n",
       "4            0      0              0          0            0             0   \n",
       "\n",
       "   Pleural Effusion  Pleural Other  Fracture  Support Devices  No Finding  \\\n",
       "0                 0              1         1                0           0   \n",
       "1                 0              1         1                0           0   \n",
       "2                 0              0         0                0           1   \n",
       "3                 0              0         0                0           1   \n",
       "4                 0              0         0                1           0   \n",
       "\n",
       "                 EncodedLabels  \n",
       "0  1,1,1,1,0,1,1,1,0,0,1,1,0,0  \n",
       "1  1,1,1,1,0,1,1,1,0,0,1,1,0,0  \n",
       "2  0,0,0,0,0,0,0,0,0,0,0,0,0,1  \n",
       "3  0,0,0,0,0,0,0,0,0,0,0,0,0,1  \n",
       "4  0,0,0,0,0,0,0,0,0,0,0,0,1,0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myCSV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e9182ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up the dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, label_col, transform = None):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.label_col = label_col\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "\n",
    "        # get the filename of the image\n",
    "        filename = self.df.iloc[index, 0]\n",
    "        label = self.df[self.label_col].iloc[index]\n",
    "\n",
    "        if type(label) == str:\n",
    "            label = [int(x) for x in label.split(\",\")]\n",
    "\n",
    "        # load the image from disk\n",
    "        path = os.path.join(self.root_dir, filename)\n",
    "        img = io.imread(path)\n",
    "\n",
    "\n",
    "\n",
    "        label = torch.tensor(label)\n",
    "        label = label.float()\n",
    "        img = torch.tensor(img)\n",
    "        img = img.resize_((224, 224))\n",
    "        img = repeat(img, \"h w -> (repeat h) w\", repeat = 3)\n",
    "        img = rearrange(img, \"(c h) w -> c h w\", c = 3)\n",
    "        img = img.float()\n",
    "\n",
    "\n",
    "        # if self.transform:\n",
    "            # label = self.transform(label)\n",
    "            # img = self.transform(img)\n",
    "\n",
    "        # return the image and its filename\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edaa3710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9d6710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dataset, validation_dataset,config, benchmark=0.33):\n",
    "    #, epochs=1\n",
    "    start_time = time.time()\n",
    "    \n",
    "    learning_rate=config[\"lr\"]\n",
    "    batch_size=config[\"batch_size\"]\n",
    "    #dropout=config[\"d1\"]\n",
    "    epochs=config[\"epochs\"]\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset,batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    \n",
    "    # information about the pretrained models is coming from this link: \n",
    "    #https://pytorch.org/vision/master/models.html\n",
    "\n",
    "\n",
    "    # just use the default weights. These should yeild the best results\n",
    "    weights = ViT_B_16_Weights.DEFAULT\n",
    "    num_classes = 14\n",
    "    feature_extraction = False\n",
    "    model = vit_b_16(weights = weights)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    if feature_extraction: \n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # change the last layer to have the correct number of classes\n",
    "        model.heads = nn.Sequential(nn.Linear(768, num_classes))\n",
    "        model.heads.requires_grad_ = True\n",
    "    else:\n",
    "        model.heads = nn.Sequential(nn.Linear(768, num_classes))\n",
    "\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9) \n",
    "    \n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    validation_accuracies =[]\n",
    "    ####\n",
    "    #prev_epoch_accuracy=0.00001 #Just above zero\n",
    "    ####\n",
    "    for epoch in range(epochs):\n",
    "        phase = 'train'\n",
    "        # set the model to training mode\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "    \n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # ugh. This is gross. I should have done this step at the beginning for all of the datasets. \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # print(\"Here's the size of the inputs: \", inputs.size())\n",
    "            # with torch.set_grad_enabled(phase == 'train'):\n",
    "                # run the training data through the model\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            #calculate the loss of the model\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        \n",
    "            if i % 100 == 99:    # record loss and test validation set\n",
    "                model.eval()\n",
    "                v_running_loss = 0.0\n",
    "                \n",
    "                ####\n",
    "                #total = 0\n",
    "                #correct = 0\n",
    "                #accuracy=0\n",
    "                #####\n",
    "                \n",
    "                for v, data in enumerate(val_loader):\n",
    "                    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                    v_outputs = model(inputs)\n",
    "                    v_loss = criterion(v_outputs, labels)\n",
    "                    v_running_loss += v_loss.item()\n",
    "                    \n",
    "                    ####\n",
    "                    #_, predicted = torch.max(v_outputs.data,1)\n",
    "                    #total += labels.size(0)\n",
    "                    #correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    #vloss = criterion(v_outputs,labels)\n",
    "                    #validation_running_loss += vloss.item()\n",
    "                    ####\n",
    "                ####\n",
    "                #accuracy = correct/total\n",
    "                #accuracy == (true == mdl(x).max(1).item()) / true.size(0)\n",
    "                ####\n",
    "                \n",
    "                print(\"Time: \", datetime.datetime.now().strftime(\"%H:%M:%S\"), \"\\tepoch: \", epoch+1, \"batch: \", i+1, \"Training loss: \", running_loss, \"Validation loss \", v_running_loss)\n",
    "                #print(\"Time: \", datetime.datetime.now().strftime(\"%H:%M:%S\"), \"\\tepoch: \", epoch+1, \"batch: \", i+1, \"Training loss: \", running_loss, \"Validation loss \", v_running_loss, \"Validation accuracy: \", accuracy)\n",
    "                validation_losses.append(v_running_loss)\n",
    "                training_losses.append(running_loss)\n",
    "                running_loss = 0.0\n",
    "                \n",
    "                ####\n",
    "                #If first epoch accuracy is less than the benchmark, then break\n",
    "                #if accuracy < benchmark:\n",
    "                #    break\n",
    "                #\n",
    "                #If less than a 1% improvement in accuracy, terminate early.\n",
    "                #epoch_acc_change = (accuracy - prev_epoch_accuracy)/prev_epoch_accuracy\n",
    "                #if epoch_acc_change < 0.01:\n",
    "                #    break\n",
    "                #prev_epoch_accuracy = accuracy\n",
    "                ####\n",
    "\n",
    "            # once the validation has been completed, update the model\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # set model back to training mode\n",
    "\n",
    "    end_time = time.time()\n",
    "    train_time = end_time - start_time\n",
    "    print(\"Elapsed Training Time: \", datetime.timedelta(seconds = train_time))\n",
    "    print('Finished Training')\n",
    "    \n",
    "    #model_name= \"vitb_model_e\" + str(epochs) + f\"_drop{dropout:.0e}\" + f\"_lr{learning_rate:.0e}\" + \"_bs \"+ str(batch_size)\n",
    "    model_name= \"vitb_model_e\" + str(epochs) + f\"_lr{learning_rate:.0e}\" + \"_bs \"+ str(batch_size)\n",
    "    model_filepath=\"../Logging/\" + model_name + \".pth\"\n",
    "\n",
    "    figure_path=\"../Logging/\" + model_name + \".png\"\n",
    "\n",
    "    print(model_filepath)\n",
    "\n",
    "    torch.save(model.state_dict(), model_filepath)\n",
    "\n",
    "    fig, axs = plt.subplots()\n",
    "    axs.plot(training_losses)\n",
    "    axs.plot(validation_losses)\n",
    "    axs.set_title(\"Losses\")\n",
    "    axs.set_xlabel(\"Epochs\")\n",
    "    axs.set_ylabel(\"Loss\")\n",
    "\n",
    "    fig.suptitle(model_name)\n",
    "    plt.savefig(figure_path, dpi=300)\n",
    "    \n",
    "    #return running_loss, v_running_loss, accuracy, epoch\n",
    "    return running_loss, v_running_loss, epoch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b3121d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Length:  21441\n",
      "Validation Length:  3063\n",
      "Test Length:  6126\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset(frontalCSV, root_dir=root_path, label_col=\"EncodedLabels\", transform=default_transform)\n",
    "\n",
    "#print(type(dataset))\n",
    "\n",
    "# split into test train validate\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = int(0.2 * len(dataset))\n",
    "\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "print(\"Train Length: \", len(train_dataset))\n",
    "print(\"Validation Length: \", len(val_dataset))\n",
    "print(\"Test Length: \", len(test_dataset))\n",
    "\n",
    "#train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=batchsize, shuffle=False)\n",
    "#test_loader = DataLoader(test_dataset,batch_size=batchsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e5c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'lr': 1, 'batch_size': 2}\n",
      "Train Start. Iteration:  1\n",
      "Time:  17:48:19 \tepoch:  1 batch:  100 Training loss:  nan Validation loss  nan\n",
      "Time:  17:48:40 \tepoch:  1 batch:  200 Training loss:  nan Validation loss  nan\n",
      "Time:  17:49:02 \tepoch:  1 batch:  300 Training loss:  nan Validation loss  nan\n",
      "Time:  17:49:23 \tepoch:  1 batch:  400 Training loss:  nan Validation loss  nan\n",
      "Time:  17:49:44 \tepoch:  1 batch:  500 Training loss:  nan Validation loss  nan\n",
      "Time:  17:50:05 \tepoch:  1 batch:  600 Training loss:  nan Validation loss  nan\n",
      "Time:  17:50:26 \tepoch:  1 batch:  700 Training loss:  nan Validation loss  nan\n",
      "Time:  17:50:47 \tepoch:  1 batch:  800 Training loss:  nan Validation loss  nan\n",
      "Time:  17:51:08 \tepoch:  1 batch:  900 Training loss:  nan Validation loss  nan\n",
      "Time:  17:51:29 \tepoch:  1 batch:  1000 Training loss:  nan Validation loss  nan\n",
      "Time:  17:51:50 \tepoch:  1 batch:  1100 Training loss:  nan Validation loss  nan\n",
      "Time:  17:52:11 \tepoch:  1 batch:  1200 Training loss:  nan Validation loss  nan\n",
      "Time:  17:52:32 \tepoch:  1 batch:  1300 Training loss:  nan Validation loss  nan\n",
      "Time:  17:52:53 \tepoch:  1 batch:  1400 Training loss:  nan Validation loss  nan\n",
      "Time:  17:53:15 \tepoch:  1 batch:  1500 Training loss:  nan Validation loss  nan\n",
      "Time:  17:53:36 \tepoch:  1 batch:  1600 Training loss:  nan Validation loss  nan\n",
      "Time:  17:53:57 \tepoch:  1 batch:  1700 Training loss:  nan Validation loss  nan\n",
      "Time:  17:54:18 \tepoch:  1 batch:  1800 Training loss:  nan Validation loss  nan\n",
      "Time:  17:54:38 \tepoch:  1 batch:  1900 Training loss:  nan Validation loss  nan\n",
      "Time:  17:54:59 \tepoch:  1 batch:  2000 Training loss:  nan Validation loss  nan\n",
      "Time:  17:55:20 \tepoch:  1 batch:  2100 Training loss:  nan Validation loss  nan\n",
      "Time:  17:55:41 \tepoch:  1 batch:  2200 Training loss:  nan Validation loss  nan\n",
      "Time:  17:56:02 \tepoch:  1 batch:  2300 Training loss:  nan Validation loss  nan\n",
      "Time:  17:56:23 \tepoch:  1 batch:  2400 Training loss:  nan Validation loss  nan\n",
      "Time:  17:56:44 \tepoch:  1 batch:  2500 Training loss:  nan Validation loss  nan\n",
      "Time:  17:57:05 \tepoch:  1 batch:  2600 Training loss:  nan Validation loss  nan\n",
      "Time:  17:57:26 \tepoch:  1 batch:  2700 Training loss:  nan Validation loss  nan\n",
      "Time:  17:57:47 \tepoch:  1 batch:  2800 Training loss:  nan Validation loss  nan\n",
      "Time:  17:58:08 \tepoch:  1 batch:  2900 Training loss:  nan Validation loss  nan\n",
      "Time:  17:58:29 \tepoch:  1 batch:  3000 Training loss:  nan Validation loss  nan\n",
      "Time:  17:58:50 \tepoch:  1 batch:  3100 Training loss:  nan Validation loss  nan\n",
      "Time:  17:59:11 \tepoch:  1 batch:  3200 Training loss:  nan Validation loss  nan\n",
      "Time:  17:59:32 \tepoch:  1 batch:  3300 Training loss:  nan Validation loss  nan\n",
      "Time:  17:59:52 \tepoch:  1 batch:  3400 Training loss:  nan Validation loss  nan\n",
      "Time:  18:00:13 \tepoch:  1 batch:  3500 Training loss:  nan Validation loss  nan\n",
      "Time:  18:00:34 \tepoch:  1 batch:  3600 Training loss:  nan Validation loss  nan\n",
      "Time:  18:00:55 \tepoch:  1 batch:  3700 Training loss:  nan Validation loss  nan\n",
      "Time:  18:01:16 \tepoch:  1 batch:  3800 Training loss:  nan Validation loss  nan\n",
      "Time:  18:01:37 \tepoch:  1 batch:  3900 Training loss:  nan Validation loss  nan\n",
      "Time:  18:01:58 \tepoch:  1 batch:  4000 Training loss:  nan Validation loss  nan\n",
      "Time:  18:02:19 \tepoch:  1 batch:  4100 Training loss:  nan Validation loss  nan\n",
      "Time:  18:02:40 \tepoch:  1 batch:  4200 Training loss:  nan Validation loss  nan\n",
      "Time:  18:03:00 \tepoch:  1 batch:  4300 Training loss:  nan Validation loss  nan\n",
      "Time:  18:03:21 \tepoch:  1 batch:  4400 Training loss:  nan Validation loss  nan\n",
      "Time:  18:03:42 \tepoch:  1 batch:  4500 Training loss:  nan Validation loss  nan\n",
      "Time:  18:04:03 \tepoch:  1 batch:  4600 Training loss:  nan Validation loss  nan\n",
      "Time:  18:04:24 \tepoch:  1 batch:  4700 Training loss:  nan Validation loss  nan\n",
      "Time:  18:04:45 \tepoch:  1 batch:  4800 Training loss:  nan Validation loss  nan\n",
      "Time:  18:05:06 \tepoch:  1 batch:  4900 Training loss:  nan Validation loss  nan\n",
      "Time:  18:05:27 \tepoch:  1 batch:  5000 Training loss:  nan Validation loss  nan\n",
      "Time:  18:05:48 \tepoch:  1 batch:  5100 Training loss:  nan Validation loss  nan\n",
      "Time:  18:06:09 \tepoch:  1 batch:  5200 Training loss:  nan Validation loss  nan\n",
      "Time:  18:06:30 \tepoch:  1 batch:  5300 Training loss:  nan Validation loss  nan\n",
      "Time:  18:06:51 \tepoch:  1 batch:  5400 Training loss:  nan Validation loss  nan\n",
      "Time:  18:07:12 \tepoch:  1 batch:  5500 Training loss:  nan Validation loss  nan\n",
      "Time:  18:07:32 \tepoch:  1 batch:  5600 Training loss:  nan Validation loss  nan\n",
      "Time:  18:07:53 \tepoch:  1 batch:  5700 Training loss:  nan Validation loss  nan\n",
      "Time:  18:08:14 \tepoch:  1 batch:  5800 Training loss:  nan Validation loss  nan\n",
      "Time:  18:08:35 \tepoch:  1 batch:  5900 Training loss:  nan Validation loss  nan\n",
      "Time:  18:08:56 \tepoch:  1 batch:  6000 Training loss:  nan Validation loss  nan\n",
      "Time:  18:09:17 \tepoch:  1 batch:  6100 Training loss:  nan Validation loss  nan\n",
      "Time:  18:09:38 \tepoch:  1 batch:  6200 Training loss:  nan Validation loss  nan\n",
      "Time:  18:09:59 \tepoch:  1 batch:  6300 Training loss:  nan Validation loss  nan\n",
      "Time:  18:10:20 \tepoch:  1 batch:  6400 Training loss:  nan Validation loss  nan\n",
      "Time:  18:10:41 \tepoch:  1 batch:  6500 Training loss:  nan Validation loss  nan\n",
      "Time:  18:11:02 \tepoch:  1 batch:  6600 Training loss:  nan Validation loss  nan\n",
      "Time:  18:11:24 \tepoch:  1 batch:  6700 Training loss:  nan Validation loss  nan\n",
      "Time:  18:11:45 \tepoch:  1 batch:  6800 Training loss:  nan Validation loss  nan\n",
      "Time:  18:12:06 \tepoch:  1 batch:  6900 Training loss:  nan Validation loss  nan\n",
      "Time:  18:12:27 \tepoch:  1 batch:  7000 Training loss:  nan Validation loss  nan\n",
      "Time:  18:12:48 \tepoch:  1 batch:  7100 Training loss:  nan Validation loss  nan\n",
      "Time:  18:13:09 \tepoch:  1 batch:  7200 Training loss:  nan Validation loss  nan\n",
      "Time:  18:13:30 \tepoch:  1 batch:  7300 Training loss:  nan Validation loss  nan\n",
      "Time:  18:13:51 \tepoch:  1 batch:  7400 Training loss:  nan Validation loss  nan\n",
      "Time:  18:14:12 \tepoch:  1 batch:  7500 Training loss:  nan Validation loss  nan\n",
      "Time:  18:14:34 \tepoch:  1 batch:  7600 Training loss:  nan Validation loss  nan\n",
      "Time:  18:14:54 \tepoch:  1 batch:  7700 Training loss:  nan Validation loss  nan\n",
      "Time:  18:15:15 \tepoch:  1 batch:  7800 Training loss:  nan Validation loss  nan\n",
      "Time:  18:15:36 \tepoch:  1 batch:  7900 Training loss:  nan Validation loss  nan\n",
      "Time:  18:15:57 \tepoch:  1 batch:  8000 Training loss:  nan Validation loss  nan\n",
      "Time:  18:16:18 \tepoch:  1 batch:  8100 Training loss:  nan Validation loss  nan\n",
      "Time:  18:16:39 \tepoch:  1 batch:  8200 Training loss:  nan Validation loss  nan\n",
      "Time:  18:17:00 \tepoch:  1 batch:  8300 Training loss:  nan Validation loss  nan\n",
      "Time:  18:17:21 \tepoch:  1 batch:  8400 Training loss:  nan Validation loss  nan\n",
      "Time:  18:17:41 \tepoch:  1 batch:  8500 Training loss:  nan Validation loss  nan\n",
      "Time:  18:18:03 \tepoch:  1 batch:  8600 Training loss:  nan Validation loss  nan\n",
      "Time:  18:18:24 \tepoch:  1 batch:  8700 Training loss:  nan Validation loss  nan\n",
      "Time:  18:18:44 \tepoch:  1 batch:  8800 Training loss:  nan Validation loss  nan\n",
      "Time:  18:19:06 \tepoch:  1 batch:  8900 Training loss:  nan Validation loss  nan\n",
      "Time:  18:19:27 \tepoch:  1 batch:  9000 Training loss:  nan Validation loss  nan\n",
      "Time:  18:19:47 \tepoch:  1 batch:  9100 Training loss:  nan Validation loss  nan\n",
      "Time:  18:20:09 \tepoch:  1 batch:  9200 Training loss:  nan Validation loss  nan\n",
      "Time:  18:20:30 \tepoch:  1 batch:  9300 Training loss:  nan Validation loss  nan\n",
      "Time:  18:20:51 \tepoch:  1 batch:  9400 Training loss:  nan Validation loss  nan\n",
      "Time:  18:21:12 \tepoch:  1 batch:  9500 Training loss:  nan Validation loss  nan\n",
      "Time:  18:21:33 \tepoch:  1 batch:  9600 Training loss:  nan Validation loss  nan\n",
      "Time:  18:21:54 \tepoch:  1 batch:  9700 Training loss:  nan Validation loss  nan\n",
      "Time:  18:22:15 \tepoch:  1 batch:  9800 Training loss:  nan Validation loss  nan\n",
      "Time:  18:22:36 \tepoch:  1 batch:  9900 Training loss:  nan Validation loss  nan\n",
      "Time:  18:22:57 \tepoch:  1 batch:  10000 Training loss:  nan Validation loss  nan\n",
      "Time:  18:23:18 \tepoch:  1 batch:  10100 Training loss:  nan Validation loss  nan\n",
      "Time:  18:23:39 \tepoch:  1 batch:  10200 Training loss:  nan Validation loss  nan\n",
      "Time:  18:23:59 \tepoch:  1 batch:  10300 Training loss:  nan Validation loss  nan\n",
      "Time:  18:24:20 \tepoch:  1 batch:  10400 Training loss:  nan Validation loss  nan\n",
      "Time:  18:24:41 \tepoch:  1 batch:  10500 Training loss:  nan Validation loss  nan\n",
      "Time:  18:25:02 \tepoch:  1 batch:  10600 Training loss:  nan Validation loss  nan\n",
      "Time:  18:25:23 \tepoch:  1 batch:  10700 Training loss:  nan Validation loss  nan\n",
      "Elapsed Training Time:  0:37:29.193238\n",
      "Finished Training\n",
      "../Logging/vitb_model_e1_lr1e+00_bs 2.pth\n",
      "{'epochs': 1, 'lr': 0.1, 'batch_size': 2}\n",
      "Train Start. Iteration:  2\n",
      "Time:  18:25:46 \tepoch:  1 batch:  100 Training loss:  71.7576225399971 Validation loss  1004.9467157125473\n",
      "Time:  18:26:07 \tepoch:  1 batch:  200 Training loss:  61.037349462509155 Validation loss  893.0876403152943\n",
      "Time:  18:26:28 \tepoch:  1 batch:  300 Training loss:  59.208206951618195 Validation loss  890.1966742575169\n",
      "Time:  18:26:49 \tepoch:  1 batch:  400 Training loss:  58.38506230711937 Validation loss  970.8355828076601\n",
      "Time:  18:27:10 \tepoch:  1 batch:  500 Training loss:  61.10953226685524 Validation loss  904.4111948609352\n",
      "Time:  18:27:32 \tepoch:  1 batch:  600 Training loss:  59.66687110066414 Validation loss  882.3762797117233\n",
      "Time:  18:27:53 \tepoch:  1 batch:  700 Training loss:  56.116371750831604 Validation loss  875.712900698185\n",
      "Time:  18:28:13 \tepoch:  1 batch:  800 Training loss:  58.54571729898453 Validation loss  877.1866931915283\n",
      "Time:  18:28:34 \tepoch:  1 batch:  900 Training loss:  58.56404295563698 Validation loss  878.8991266191006\n",
      "Time:  18:28:56 \tepoch:  1 batch:  1000 Training loss:  57.432875990867615 Validation loss  878.1839264333248\n",
      "Time:  18:29:17 \tepoch:  1 batch:  1100 Training loss:  60.837007611989975 Validation loss  911.6755630373955\n",
      "Time:  18:29:37 \tepoch:  1 batch:  1200 Training loss:  60.2766450047493 Validation loss  880.2164132595062\n",
      "Time:  18:29:59 \tepoch:  1 batch:  1300 Training loss:  57.64036828279495 Validation loss  891.1671355962753\n",
      "Time:  18:30:20 \tepoch:  1 batch:  1400 Training loss:  58.93208810687065 Validation loss  877.1077946424484\n",
      "Time:  18:30:40 \tepoch:  1 batch:  1500 Training loss:  57.53637635707855 Validation loss  880.771085113287\n",
      "Time:  18:31:02 \tepoch:  1 batch:  1600 Training loss:  54.23061087727547 Validation loss  912.0342184305191\n",
      "Time:  18:31:23 \tepoch:  1 batch:  1700 Training loss:  57.99887251853943 Validation loss  917.4931491315365\n",
      "Time:  18:31:44 \tepoch:  1 batch:  1800 Training loss:  56.73026493191719 Validation loss  906.6380444467068\n",
      "Time:  18:32:05 \tepoch:  1 batch:  1900 Training loss:  59.968240201473236 Validation loss  884.2533830702305\n",
      "Time:  18:32:26 \tepoch:  1 batch:  2000 Training loss:  57.44018033146858 Validation loss  906.6356370449066\n",
      "Time:  18:32:47 \tepoch:  1 batch:  2100 Training loss:  57.94306981563568 Validation loss  877.5718375146389\n",
      "Time:  18:33:08 \tepoch:  1 batch:  2200 Training loss:  57.06300503015518 Validation loss  884.2797682881355\n",
      "Time:  18:33:29 \tepoch:  1 batch:  2300 Training loss:  57.563831090927124 Validation loss  881.8475054204464\n",
      "Time:  18:33:50 \tepoch:  1 batch:  2400 Training loss:  59.50683110952377 Validation loss  893.7716330885887\n",
      "Time:  18:34:11 \tepoch:  1 batch:  2500 Training loss:  58.22361412644386 Validation loss  885.0141698718071\n",
      "Time:  18:34:32 \tepoch:  1 batch:  2600 Training loss:  58.31555724143982 Validation loss  880.4417220950127\n",
      "Time:  18:34:54 \tepoch:  1 batch:  2700 Training loss:  56.06867089867592 Validation loss  876.0344642698765\n",
      "Time:  18:35:15 \tepoch:  1 batch:  2800 Training loss:  56.070298701524734 Validation loss  888.0609701573849\n",
      "Time:  18:35:36 \tepoch:  1 batch:  2900 Training loss:  60.91184866428375 Validation loss  982.8221127390862\n",
      "Time:  18:35:57 \tepoch:  1 batch:  3000 Training loss:  58.092848509550095 Validation loss  918.7247018516064\n",
      "Time:  18:36:18 \tepoch:  1 batch:  3100 Training loss:  59.19393628835678 Validation loss  895.7492239773273\n",
      "Time:  18:36:40 \tepoch:  1 batch:  3200 Training loss:  57.53604644536972 Validation loss  908.7931196987629\n",
      "Time:  18:37:01 \tepoch:  1 batch:  3300 Training loss:  60.19007629156113 Validation loss  874.7937258183956\n",
      "Time:  18:37:22 \tepoch:  1 batch:  3400 Training loss:  56.72353634238243 Validation loss  875.7212229669094\n",
      "Time:  18:37:43 \tepoch:  1 batch:  3500 Training loss:  60.28446751832962 Validation loss  949.0680131614208\n",
      "Time:  18:38:04 \tepoch:  1 batch:  3600 Training loss:  59.04829478263855 Validation loss  883.2086706161499\n",
      "Time:  18:38:25 \tepoch:  1 batch:  3700 Training loss:  57.55424419045448 Validation loss  874.7050509750843\n",
      "Time:  18:38:47 \tepoch:  1 batch:  3800 Training loss:  58.45483702421188 Validation loss  875.6314619481564\n",
      "Time:  18:39:08 \tepoch:  1 batch:  3900 Training loss:  59.56750497221947 Validation loss  882.8153388798237\n",
      "Time:  18:39:29 \tepoch:  1 batch:  4000 Training loss:  57.60851579904556 Validation loss  883.653469055891\n",
      "Time:  18:39:50 \tepoch:  1 batch:  4100 Training loss:  57.850411891937256 Validation loss  875.6820358037949\n",
      "Time:  18:40:11 \tepoch:  1 batch:  4200 Training loss:  60.03540486097336 Validation loss  886.0566149353981\n",
      "Time:  18:40:32 \tepoch:  1 batch:  4300 Training loss:  58.47900912165642 Validation loss  886.4324714243412\n",
      "Time:  18:40:53 \tepoch:  1 batch:  4400 Training loss:  58.53729325532913 Validation loss  878.7913547754288\n",
      "Time:  18:41:14 \tepoch:  1 batch:  4500 Training loss:  58.36986926198006 Validation loss  881.3181583583355\n",
      "Time:  18:41:35 \tepoch:  1 batch:  4600 Training loss:  58.179073452949524 Validation loss  883.7058938741684\n",
      "Time:  18:41:56 \tepoch:  1 batch:  4700 Training loss:  59.36119470000267 Validation loss  874.6582610309124\n",
      "Time:  18:42:18 \tepoch:  1 batch:  4800 Training loss:  58.10869339108467 Validation loss  875.7703240215778\n",
      "Time:  18:42:39 \tepoch:  1 batch:  4900 Training loss:  56.88784018158913 Validation loss  877.0185931921005\n",
      "Time:  18:43:00 \tepoch:  1 batch:  5000 Training loss:  60.32446217536926 Validation loss  881.2251395583153\n",
      "Time:  18:43:21 \tepoch:  1 batch:  5100 Training loss:  56.33976700901985 Validation loss  901.24784719944\n",
      "Time:  18:43:42 \tepoch:  1 batch:  5200 Training loss:  59.49003079533577 Validation loss  875.3818630576134\n",
      "Time:  18:44:03 \tepoch:  1 batch:  5300 Training loss:  59.433626621961594 Validation loss  881.1837981641293\n",
      "Time:  18:44:24 \tepoch:  1 batch:  5400 Training loss:  58.75360304117203 Validation loss  897.4288962781429\n",
      "Time:  18:44:45 \tepoch:  1 batch:  5500 Training loss:  56.75574630498886 Validation loss  873.8365345001221\n",
      "Time:  18:45:06 \tepoch:  1 batch:  5600 Training loss:  55.630042374134064 Validation loss  886.2017593979836\n",
      "Time:  18:45:27 \tepoch:  1 batch:  5700 Training loss:  56.803496807813644 Validation loss  875.3677115142345\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "#Grid search parameters\n",
    "#dropout=[0.2]\n",
    "batch_size=[2,4,8,12]\n",
    "learn_rate=[1,0.1,0.01,0.001]\n",
    "epochs=[1,2,3]\n",
    "\n",
    "\n",
    "it=0\n",
    "#for d in dropout:\n",
    "for e in epochs:\n",
    "    for bs in batch_size:\n",
    "        for lr in learn_rate:\n",
    "\n",
    "            it +=1 \n",
    "            #config = {\"d1\": d,\"lr\": lr,\"batch_size\": bs}\n",
    "            config = {\"epochs\": e, \"lr\": lr, \"batch_size\": bs}\n",
    "            #config = {\"lr\": lr,\"batch_size\": bs}\n",
    "\n",
    "            print(config)\n",
    "            print(\"Train Start. Iteration: \",it)\n",
    "            t_loss,v_loss, end_Ep=train_model(train_dataset, val_dataset,config)\n",
    "            #t_loss,v_loss, acc, end_Ep=train_model(train_dataset, val_dataset,config)\n",
    "\n",
    "            list_row= str(bs) + \",\" + str(lr) + \",\" + str(t_loss) + \",\" + str(v_loss) + \",\" + str(end_Ep)\n",
    "            #list_row= str(bs) + \",\" + str(lr) + \",\" + str(t_loss) + \",\" + str(v_loss) + \",\" + str(end_Ep), + \",\" + str(acc)\n",
    "\n",
    "            t_list=[list_row]  \n",
    "            result_list.append(t_list)\n",
    "\n",
    "\n",
    "with open('opt_resultss.csv','w') as result_file:\n",
    "    wr = csv.writer(result_file, dialect='excel')\n",
    "    wr.writerow(result_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
