{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47cba282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from skimage import io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange, repeat\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, '../utils/')\n",
    "from dataset import ChestImage64\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.models import vit_l_16, ViT_L_16_Weights\n",
    "from torch.utils.data import random_split, DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c69150c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_path = \"../64pxImages/train_labels_64p.csv\"\n",
    "# root_path = '../64pxImages'\n",
    "\n",
    "csv_path = \"../Data/256pxImages/train_labels_256p.csv\"\n",
    "root_path = '../Data/256pxImages'\n",
    "\n",
    "\n",
    "default_transform = ViT_L_16_Weights.IMAGENET1K_SWAG_LINEAR_V1.transforms\n",
    "\n",
    "\n",
    "data_transform = Compose([\n",
    "    Resize((64, 64)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b8bdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61266, 19)\n",
      "label_test:  [1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([256, 256])\n"
     ]
    }
   ],
   "source": [
    "myCSV = pd.read_csv(csv_path)\n",
    "myCSV['EncodedLabels'] = ''\n",
    "print(myCSV.shape)\n",
    "\n",
    "\n",
    "# for i in range(4, myCSV.shape[1]-1):\n",
    "#     myCSV['EncodedLabels'] = myCSV['EncodedLabels'].astype(str) + myCSV.iloc[:, i].astype(str) \n",
    "#     if i < myCSV.shape[1]-2:\n",
    "#         myCSV['EncodedLabels'] = myCSV['EncodedLabels'].astype(str) + \",\" \n",
    "\n",
    "for i in range(4, myCSV.shape[1]-1):\n",
    "    myCSV['EncodedLabels'] = myCSV['EncodedLabels'].astype(str) + myCSV.iloc[:, i].astype(str) \n",
    "    if i < myCSV.shape[1]-2:\n",
    "        myCSV['EncodedLabels'] = myCSV['EncodedLabels'].astype(str) + \",\" \n",
    "\n",
    "\n",
    "\n",
    "# myCSV['EncodedLabels'] = myCSV['EncodedLabels'].astype(str) + \"]\"\n",
    "\n",
    "\n",
    "# We can use the encodedlabels column as our labels for our data\n",
    "\n",
    "# since we are not useing cross attention, pull out only the frontal images. \n",
    "frontalCSV = myCSV[myCSV['Frontal/Lateral'].str.contains(\"Frontal\")]\n",
    "frontalCSV.head()\n",
    "\n",
    "filename = frontalCSV.iloc[1, 0]\n",
    "label_test = frontalCSV['EncodedLabels'].iloc[0]\n",
    "\n",
    "test_path = os.path.join(root_path, filename)\n",
    "\n",
    "\n",
    "label_test = [int(x) for x in label_test.split(\",\")]\n",
    "\n",
    "print(\"label_test: \", label_test)\n",
    "\n",
    "image = io.imread(test_path)\n",
    "print(type(image))\n",
    "image = torch.tensor(image)\n",
    "print(image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "605e56bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>256path</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Study</th>\n",
       "      <th>Frontal/Lateral</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>EncodedLabels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frontal\\patient00002_study1_Frontal.png</td>\n",
       "      <td>patient00002</td>\n",
       "      <td>study1</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,1,1,1,0,1,1,1,0,0,1,1,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lateral\\patient00002_study1_Lateral.png</td>\n",
       "      <td>patient00002</td>\n",
       "      <td>study1</td>\n",
       "      <td>Lateral</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,1,1,1,0,1,1,1,0,0,1,1,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frontal\\patient00004_study1_Frontal.png</td>\n",
       "      <td>patient00004</td>\n",
       "      <td>study1</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lateral\\patient00004_study1_Lateral.png</td>\n",
       "      <td>patient00004</td>\n",
       "      <td>study1</td>\n",
       "      <td>Lateral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frontal\\patient00005_study1_Frontal.png</td>\n",
       "      <td>patient00005</td>\n",
       "      <td>study1</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,1,0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   256path       Patient   Study  \\\n",
       "0  Frontal\\patient00002_study1_Frontal.png  patient00002  study1   \n",
       "1  Lateral\\patient00002_study1_Lateral.png  patient00002  study1   \n",
       "2  Frontal\\patient00004_study1_Frontal.png  patient00004  study1   \n",
       "3  Lateral\\patient00004_study1_Lateral.png  patient00004  study1   \n",
       "4  Frontal\\patient00005_study1_Frontal.png  patient00005  study1   \n",
       "\n",
       "  Frontal/Lateral  Enlarged Cardiomediastinum  Cardiomegaly  Lung Opacity  \\\n",
       "0         Frontal                           1             1             1   \n",
       "1         Lateral                           1             1             1   \n",
       "2         Frontal                           0             0             0   \n",
       "3         Lateral                           0             0             0   \n",
       "4         Frontal                           0             0             0   \n",
       "\n",
       "   Lung Lesion  Edema  Consolidation  Pneumonia  Atelectasis  Pneumothorax  \\\n",
       "0            1      0              1          1            1             0   \n",
       "1            1      0              1          1            1             0   \n",
       "2            0      0              0          0            0             0   \n",
       "3            0      0              0          0            0             0   \n",
       "4            0      0              0          0            0             0   \n",
       "\n",
       "   Pleural Effusion  Pleural Other  Fracture  Support Devices  No Finding  \\\n",
       "0                 0              1         1                0           0   \n",
       "1                 0              1         1                0           0   \n",
       "2                 0              0         0                0           1   \n",
       "3                 0              0         0                0           1   \n",
       "4                 0              0         0                1           0   \n",
       "\n",
       "                 EncodedLabels  \n",
       "0  1,1,1,1,0,1,1,1,0,0,1,1,0,0  \n",
       "1  1,1,1,1,0,1,1,1,0,0,1,1,0,0  \n",
       "2  0,0,0,0,0,0,0,0,0,0,0,0,0,1  \n",
       "3  0,0,0,0,0,0,0,0,0,0,0,0,0,1  \n",
       "4  0,0,0,0,0,0,0,0,0,0,0,0,1,0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myCSV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e9182ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up the dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, label_col, transform = None):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.label_col = label_col\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "\n",
    "        # get the filename of the image\n",
    "        filename = self.df.iloc[index, 0]\n",
    "        label = self.df[self.label_col].iloc[index]\n",
    "\n",
    "        if type(label) == str:\n",
    "            label = [int(x) for x in label.split(\",\")]\n",
    "\n",
    "        # load the image from disk\n",
    "        path = os.path.join(self.root_dir, filename)\n",
    "        img = io.imread(path)\n",
    "\n",
    "\n",
    "\n",
    "        label = torch.tensor(label)\n",
    "        label = label.float()\n",
    "        img = torch.tensor(img)\n",
    "        img = img.resize_((224, 224))\n",
    "        img = repeat(img, \"h w -> (repeat h) w\", repeat = 3)\n",
    "        img = rearrange(img, \"(c h) w -> c h w\", c = 3)\n",
    "        img = img.float()\n",
    "\n",
    "\n",
    "        # if self.transform:\n",
    "            # label = self.transform(label)\n",
    "            # img = self.transform(img)\n",
    "\n",
    "        # return the image and its filename\n",
    "        return img, label\n",
    "    \n",
    "\n",
    "#dataset = CustomDataset(frontalCSV, root_dir=root_path, label_col=\"EncodedLabels\", transform=default_transform)\n",
    "\n",
    "#print(type(dataset))\n",
    "\n",
    "# split into test train validate\n",
    "#train_size = int(0.7 * len(dataset))\n",
    "#val_size = int(0.1 * len(dataset))\n",
    "#test_size = int(0.2 * len(dataset))\n",
    "\n",
    "\n",
    "#train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "#print(\"Train Length: \", len(train_dataset))\n",
    "#print(\"Validation Length: \", len(val_dataset))\n",
    "#print(\"Test Length: \", len(test_dataset))\n",
    "\n",
    "#batchsize = 32\n",
    "\n",
    "# make three different dataloaders\n",
    "#train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=batchsize, shuffle=False)\n",
    "#test_loader = DataLoader(test_dataset,batch_size=batchsize, shuffle=True)\n",
    "\n",
    "\n",
    "#features, labels = next(iter(train_loader))\n",
    "#print(features.size())\n",
    "#print(features.dtype)\n",
    "\n",
    "#print(features[1, 1, :, :])\n",
    "\n",
    "#print(labels.size())\n",
    "#print(datetime.datetime.now().strftime(\"%H:%M:%S\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "313c0d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# information about the pretrained models is coming from this link: \n",
    "#https://pytorch.org/vision/master/models.html\n",
    "\n",
    "\n",
    "# just use the default weights. These should yeild the best results\n",
    "#weights = ViT_L_16_Weights.DEFAULT\n",
    "#num_classes = 14\n",
    "#feature_extraction = False\n",
    "#model = vit_l_16(weights = weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e733e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs = 1\n",
    "#learning_rate = 0.1\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "#if feature_extraction: \n",
    "#    for param in model.parameters():\n",
    "#        param.requires_grad = False\n",
    "\n",
    "    # change the last layer to have the correct number of classes\n",
    "#    model.heads = nn.Sequential(nn.Linear(1024, num_classes))\n",
    "#    model.heads.requires_grad_ = True\n",
    "#else:\n",
    "#        model.heads = nn.Sequential(nn.Linear(1024, num_classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edaa3710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9d6710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dataset, validation_dataset,config, benchmark=0.33, epochs=1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    dropout=config[\"d1\"]\n",
    "    # information about the pretrained models is coming from this link: \n",
    "    #https://pytorch.org/vision/master/models.html\n",
    "\n",
    "\n",
    "    # just use the default weights. These should yeild the best results\n",
    "    weights = ViT_L_16_Weights.DEFAULT\n",
    "    num_classes = 14\n",
    "    feature_extraction = False\n",
    "    model = vit_l_16(weights = weights)\n",
    "\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "    learning_rate=config[\"lr\"]\n",
    "    batch_size=config[\"batch_size\"]\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9) \n",
    "    \n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        phase = 'train'\n",
    "        # set the model to training mode\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "    \n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # ugh. This is gross. I should have done this step at the beginning for all of the datasets. \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # print(\"Here's the size of the inputs: \", inputs.size())\n",
    "            # with torch.set_grad_enabled(phase == 'train'):\n",
    "                # run the training data through the model\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            #calculate the loss of the model\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "            if i % 100 == 99:    # record loss and test validation set\n",
    "                model.eval()\n",
    "                v_running_loss = 0.0\n",
    "                for v, vdata in enumerate(val_loader):\n",
    "                    v_inputs, v_labels = vdata[0].to(device), vdata[1].to(device)\n",
    "                    v_outputs = model(v_inputs)\n",
    "                    v_loss = criterion(v_outputs, v_labels)\n",
    "                    v_running_loss += v_loss.item()\n",
    "\n",
    "                print(\"Time: \", datetime.datetime.now().strftime(\"%H:%M:%S\"), \"\\tepoch: \", epoch+1, \"batch: \", i+1, \"Training loss: \", running_loss, \"Validation loss \", v_running_loss)\n",
    "                validation_losses.append(v_running_loss)\n",
    "                training_losses.append(running_loss)\n",
    "                running_loss = 0.0\n",
    "        \n",
    "\n",
    "            # once the validation has been completed, update the model\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # set model back to training mode\n",
    "\n",
    "    end_time = time.time()\n",
    "    train_time = end_time - start_time\n",
    "    print(\"Elapsed Training Time: \", datetime.timedelta(seconds = train_time))\n",
    "    print('Finished Training')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d9a1b91",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m batch_size\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m32\u001b[39m]\n\u001b[0;32m      6\u001b[0m learn_rate\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1e-3\u001b[39m]\n\u001b[1;32m----> 8\u001b[0m trainset \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#trainset, testset = load_data()\u001b[39;00m\n\u001b[0;32m     11\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(trainset))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_data' is not defined"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "#Grid search parameters\n",
    "dropout=[0.2]\n",
    "batch_size=[32]\n",
    "learn_rate=[1e-3]\n",
    "\n",
    "trainset = load_data()\n",
    "#trainset, testset = load_data()\n",
    "\n",
    "train_size = int(0.8*len(trainset))\n",
    "validation_size = len(trainset) - train_size\n",
    "\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(trainset, [train_size, validation_size])\n",
    "\n",
    "it=0\n",
    "for d in dropout:\n",
    "    for bs in batch_size:\n",
    "        for lr in learn_rate:\n",
    "\n",
    "            it +=1 \n",
    "            config = {\"d1\": d,\"lr\": lr,\"batch_size\": bs}\n",
    "            \n",
    "            print(\"Train Start. Iteration: \",it)\n",
    "            t_loss,v_loss,v_acc,end_Ep=train_model(train_dataset, validation_dataset,config)\n",
    "\n",
    "            list_row=str(d) + \",\" + str(bs) + \",\" + str(lr) + \",\" + str(t_loss) + \",\" + str(v_loss) + \",\" + str(v_acc) + \",\" + str(end_Ep)\n",
    "\n",
    "            t_list=[list_row]  \n",
    "            result_list.append(t_list)\n",
    "\n",
    "\n",
    "with open('opt_resultss.csv','w') as result_file:\n",
    "    wr = csv.writer(result_file, dialect='excel')\n",
    "    wr.writerow(result_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
