{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dba2c58-ae24-4bc4-bba2-104d8feb885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from skimage import io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange, repeat\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, '../utils/')\n",
    "from dataset import ChestImage64\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.models import vit_l_16, ViT_L_16_Weights,vit_b_16, ViT_B_16_Weights\n",
    "from torch.utils.data import random_split, DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1595199-4e45-4c84-b410-9b90afb5c57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30630, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Front Path</th>\n",
       "      <th>Lateral path</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Study</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>EncodedLabels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frontal/patient00002_study1_Frontal.png</td>\n",
       "      <td>Lateral/patient00002_study1_Lateral.png</td>\n",
       "      <td>patient00002</td>\n",
       "      <td>study1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,1,1,1,0,1,1,1,0,0,1,1,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frontal/patient00004_study1_Frontal.png</td>\n",
       "      <td>Lateral/patient00004_study1_Lateral.png</td>\n",
       "      <td>patient00004</td>\n",
       "      <td>study1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frontal/patient00005_study1_Frontal.png</td>\n",
       "      <td>Lateral/patient00005_study1_Lateral.png</td>\n",
       "      <td>patient00005</td>\n",
       "      <td>study1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,1,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Frontal/patient00009_study1_Frontal.png</td>\n",
       "      <td>Lateral/patient00009_study1_Lateral.png</td>\n",
       "      <td>patient00009</td>\n",
       "      <td>study1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1,1,0,0,0,0,0,0,0,0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frontal/patient00010_study1_Frontal.png</td>\n",
       "      <td>Lateral/patient00010_study1_Lateral.png</td>\n",
       "      <td>patient00010</td>\n",
       "      <td>study1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0,1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Front Path  \\\n",
       "0  Frontal/patient00002_study1_Frontal.png   \n",
       "1  Frontal/patient00004_study1_Frontal.png   \n",
       "2  Frontal/patient00005_study1_Frontal.png   \n",
       "3  Frontal/patient00009_study1_Frontal.png   \n",
       "4  Frontal/patient00010_study1_Frontal.png   \n",
       "\n",
       "                              Lateral path       Patient   Study  \\\n",
       "0  Lateral/patient00002_study1_Lateral.png  patient00002  study1   \n",
       "1  Lateral/patient00004_study1_Lateral.png  patient00004  study1   \n",
       "2  Lateral/patient00005_study1_Lateral.png  patient00005  study1   \n",
       "3  Lateral/patient00009_study1_Lateral.png  patient00009  study1   \n",
       "4  Lateral/patient00010_study1_Lateral.png  patient00010  study1   \n",
       "\n",
       "   Enlarged Cardiomediastinum  Cardiomegaly  Lung Opacity  Lung Lesion  Edema  \\\n",
       "0                           1             1             1            1      0   \n",
       "1                           0             0             0            0      0   \n",
       "2                           0             0             0            0      0   \n",
       "3                           1             1             0            0      0   \n",
       "4                           0             0             0            0      0   \n",
       "\n",
       "   Consolidation  Pneumonia  Atelectasis  Pneumothorax  Pleural Effusion  \\\n",
       "0              1          1            1             0                 0   \n",
       "1              0          0            0             0                 0   \n",
       "2              0          0            0             0                 0   \n",
       "3              0          0            0             0                 0   \n",
       "4              0          0            0             0                 0   \n",
       "\n",
       "   Pleural Other  Fracture  Support Devices  No Finding  \\\n",
       "0              1         1                0           0   \n",
       "1              0         0                0           1   \n",
       "2              0         0                1           0   \n",
       "3              0         0                0           0   \n",
       "4              0         0                0           1   \n",
       "\n",
       "                 EncodedLabels  \n",
       "0  1,1,1,1,0,1,1,1,0,0,1,1,0,0  \n",
       "1  0,0,0,0,0,0,0,0,0,0,0,0,0,1  \n",
       "2  0,0,0,0,0,0,0,0,0,0,0,0,1,0  \n",
       "3  1,1,0,0,0,0,0,0,0,0,0,0,0,0  \n",
       "4  0,0,0,0,0,0,0,0,0,0,0,0,0,1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = \"../Data/256pxImages/train_labels_256p_paired.csv\"\n",
    "root_path = '../Data/256pxImages'\n",
    "\n",
    "pairCSV = pd.read_csv(csv_path)\n",
    "pairCSV['EncodedLabels'] = ''\n",
    "print(pairCSV.shape)\n",
    "\n",
    "for i in range(4, pairCSV.shape[1]-1):\n",
    "    pairCSV['EncodedLabels'] = pairCSV['EncodedLabels'].astype(str) + pairCSV.iloc[:, i].astype(str) \n",
    "    if i < pairCSV.shape[1]-2:\n",
    "        pairCSV['EncodedLabels'] = pairCSV['EncodedLabels'].astype(str) + \",\" \n",
    "\n",
    "pairCSV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25897df6-ece8-4a98-b0c0-190040653832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_test:  [1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0]\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([256, 256])\n",
      "<class 'numpy.ndarray'>\n",
      "torch.Size([256, 256])\n"
     ]
    }
   ],
   "source": [
    "# test image loading\n",
    "front_file = pairCSV.iloc[0, 0]\n",
    "lat_file= pairCSV.iloc[0, 1]\n",
    "label_test = pairCSV['EncodedLabels'].iloc[0]\n",
    "\n",
    "test_path_front = os.path.join(root_path, front_file)\n",
    "test_path_lat = os.path.join(root_path, lat_file)\n",
    "\n",
    "label_test = [int(x) for x in label_test.split(\",\")]\n",
    "\n",
    "print(\"label_test: \", label_test)\n",
    "\n",
    "image_front = io.imread(test_path_front)\n",
    "print(type(image_front))\n",
    "image_front = torch.tensor(image_front)\n",
    "print(image_front.size())\n",
    "\n",
    "image_lat = io.imread(test_path_lat)\n",
    "print(type(image_lat))\n",
    "image_lat = torch.tensor(image_lat)\n",
    "print(image_lat.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cc79185-1584-4408-8107-4fdc677c14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up the paired dataset\n",
    "class PairedDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, label_col, transform = None):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.label_col = label_col\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "\n",
    "        # get the filename of the image\n",
    "        file_front = self.df.iloc[index, 0]\n",
    "        file_lat = self.df.iloc[index, 1]\n",
    "        label = self.df[self.label_col].iloc[index]\n",
    "\n",
    "        if type(label) == str:\n",
    "            label = [int(x) for x in label.split(\",\")]\n",
    "\n",
    "        # load the image from disk\n",
    "        front_path = os.path.join(self.root_dir, file_front)\n",
    "        lat_path = os.path.join(self.root_dir, file_lat)\n",
    "\n",
    "        img_front = io.imread(front_path)\n",
    "        img_lat = io.imread(lat_path)\n",
    "\n",
    "        label = torch.tensor(label)\n",
    "        label = label.float()\n",
    "\n",
    "        img_front = torch.tensor(img_front)\n",
    "        img_front = img_front.resize_((224, 224))\n",
    "        img_front = repeat(img_front, \"h w -> (repeat h) w\", repeat = 3)\n",
    "        img_front = rearrange(img_front, \"(c h) w -> 1 c h w\", c = 3)\n",
    "        img_front = img_front.float()\n",
    "\n",
    "        img_lat = torch.tensor(img_lat)\n",
    "        img_lat = img_lat.resize_((224, 224))\n",
    "        img_lat = repeat(img_lat, \"h w -> (repeat h) w\", repeat = 3)\n",
    "        img_lat = rearrange(img_lat, \"(c h) w -> 1 c h w\", c = 3)\n",
    "        img_lat = img_lat.float()\n",
    "\n",
    "        img_pair=torch.cat((img_front,img_lat),0)\n",
    "\n",
    "\n",
    "        # if self.transform:\n",
    "            # label = self.transform(label)\n",
    "            # img = self.transform(img)\n",
    "\n",
    "        # return the image and its filename\n",
    "        return img_pair, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54fe39b6-02bd-4a38-8a30-ea3881fa8747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.PairedDataset'>\n"
     ]
    }
   ],
   "source": [
    "default_transform = ViT_L_16_Weights.IMAGENET1K_SWAG_LINEAR_V1.transforms\n",
    "pairDataset = PairedDataset(pairCSV, root_dir=root_path, label_col=\"EncodedLabels\", transform=default_transform)\n",
    "\n",
    "print(type(pairDataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14088383-f278-4b35-a460-5432a8f9bb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Length:  21441\n",
      "Validation Length:  3063\n",
      "Test Length:  6126\n"
     ]
    }
   ],
   "source": [
    "# split into test train validate\n",
    "train_size = int(0.7 * len(pairDataset))\n",
    "val_size = int(0.1 * len(pairDataset))\n",
    "test_size = int(0.2 * len(pairDataset))\n",
    "\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(pairDataset, [train_size, val_size, test_size])\n",
    "\n",
    "print(\"Train Length: \", len(train_dataset))\n",
    "print(\"Validation Length: \", len(val_dataset))\n",
    "print(\"Test Length: \", len(test_dataset))\n",
    "\n",
    "#batchsize = 8\n",
    "\n",
    "# make three different dataloaders\n",
    "#train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=batchsize, shuffle=False)\n",
    "#test_loader = DataLoader(test_dataset,batch_size=batchsize, shuffle=True)\n",
    "\n",
    "\n",
    "#features, labels = next(iter(train_loader))\n",
    "#print(features.size())\n",
    "#print(features.dtype)\n",
    "\n",
    "#print(features[1, 1, :, :])\n",
    "\n",
    "#print(labels.size())\n",
    "#print(datetime.datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be191acd-1326-4417-8c4a-ec768ab96da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#front_features=features[:, 0, :, :, :]\n",
    "#print(front_features.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16e1b633-6579-483d-996f-697a0c836f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lat_features=features[:, 1, :, :, :]\n",
    "#print(lat_features.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8875744-33f1-4768-a519-96838f1d9419",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllAttentionVIT(nn.Module):\n",
    "    def __init__(self,weights_frontal,weights_lateral,code_size,num_classes,bottleneck=1024,drop_rate=0.1):\n",
    "        \n",
    "        super(AllAttentionVIT,self).__init__()\n",
    "\n",
    "        #Initialize the model\n",
    "        self.transformer_enc_frontal = vit_b_16(weights = weights_frontal)\n",
    "        self.transformer_enc_frontal.heads = nn.Sequential(nn.Linear(768, code_size))\n",
    "        self.transformer_enc_lateral = vit_b_16(weights = weights_lateral)\n",
    "        self.transformer_enc_lateral.heads = nn.Sequential(nn.Linear(768, code_size))\n",
    "\n",
    "        self.dropout = nn.Dropout(p = drop_rate)\n",
    "        self.ff = nn.Linear(code_size*2,num_classes)\n",
    "\n",
    "    #Expect two images with the same class.\n",
    "    def forward(self,x):\n",
    "\n",
    "        #Split up paired images\n",
    "        x_f=x[:, 0, :, :, :]\n",
    "        x_l=x[:, 1, :, :, :]\n",
    "        \n",
    "        #Encode front and lateral embeddings\n",
    "        x_f = self.transformer_enc_frontal(x_f)\n",
    "        x_l = self.transformer_enc_frontal(x_l)\n",
    "\n",
    "        #Concat embeddings. May want to experiment with convolutions.\n",
    "        x = torch.cat((x_f,x_l),1)\n",
    "\n",
    "        #Map concatenated embeddings onto the classes\n",
    "        x = self.dropout(x)\n",
    "        x = self.ff(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34222f22-955c-45e7-9203-60e3a7214aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testWeights=ViT_B_16_Weights.DEFAULT\n",
    "#testModel = AllAttentionVIT(testWeights,testWeights,768,14)\n",
    "\n",
    "# simple function to determine how many TRAINABILE parameters are in the model\n",
    "#def count_parameters(testModel):\n",
    "#    return sum(p.numel() for p in testModel.parameters() if p.requires_grad)\n",
    "\n",
    "#print(count_parameters(testModel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efc2707e-c1bb-470f-bc6e-f9d1cbcbdecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out a list of the parameters we are training\n",
    "#for name,param in testModel.named_parameters():\n",
    "#    if param.requires_grad == True:\n",
    "#        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac1c4e9e-9bac-4e25-9872-e6ac4654c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch accumulation parameter\n",
    "#target_accumulation=32\n",
    "#accum_iter = target_accumulation/batchsize  \n",
    "#print(accum_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9df7c58e-4855-4bc2-955d-53297b07e472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e6cc6fb-6b35-4642-a779-5a731dc6a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multimodal_model(train_dataset, validation_dataset,config, benchmark=0.33):\n",
    "    # now let's train this thing. \n",
    "    \n",
    "    #batchsize = 2\n",
    "    #epochs = 1\n",
    "    #learning_rate = 0.003\n",
    "    \n",
    "    learning_rate=config[\"lr\"]\n",
    "    batchsize=config[\"batch_size\"]\n",
    "    #dropout=config[\"d1\"]\n",
    "    epochs=config[\"epochs\"]\n",
    "    \n",
    "    # split into test train validate\n",
    "    train_size = int(0.7 * len(pairDataset))\n",
    "    val_size = int(0.1 * len(pairDataset))\n",
    "    test_size = int(0.2 * len(pairDataset))\n",
    "\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = random_split(pairDataset, [train_size, val_size, test_size])\n",
    "    \n",
    "    #default_transform = ViT_L_16_Weights.IMAGENET1K_SWAG_LINEAR_V1.transforms\n",
    "    #pairDataset = PairedDataset(pairCSV, root_dir=root_path, label_col=\"EncodedLabels\", transform=default_transform)\n",
    "    \n",
    "    target_accumulation=32\n",
    "    accum_iter = target_accumulation/batchsize  \n",
    "    #print(accum_iter)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batchsize, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset,batch_size=batchsize, shuffle=True)\n",
    "    \n",
    "    features, labels = next(iter(train_loader))\n",
    "    \n",
    "    testWeights=ViT_B_16_Weights.DEFAULT\n",
    "    testModel = AllAttentionVIT(testWeights,testWeights,768,14)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # make sure the model is running on the GPU if its available\n",
    "    testModel.to(device)\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    params_to_update = testModel.parameters()\n",
    "    optimizer = torch.optim.SGD(params_to_update, lr=learning_rate, momentum=0.9)\n",
    "\n",
    "\n",
    "    # optimizer = optim.Adam(model500k.parameters(), lr=learning_rate)\n",
    "\n",
    "    # start a clock \n",
    "    print(\"Training Starting.\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # create empty arrays to hold the loss results\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        phase = 'train'\n",
    "        # set the model to training mode\n",
    "        testModel.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "    # zero the parameter gradients at the very beginning\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # ugh. This is gross. I should have done this step at the beginning for all of the datasets. \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # print(\"Here's the size of the inputs: \", inputs.size())\n",
    "            # with torch.set_grad_enabled(phase == 'train'):\n",
    "                # run the training data through the model\n",
    "            outputs = testModel(inputs)\n",
    "\n",
    "            #calculate the loss of the model\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            #Gradient accumulation\n",
    "            loss = loss / accum_iter\n",
    "            loss.backward()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # weights update for each gradient accumulation\n",
    "            if ((i + 1) % accum_iter == 0) or (i + 1 == len(train_loader)):\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if ((i + 1) / accum_iter) % 50 == 0:    # record loss and test validation set every 50 gradient accumulations\n",
    "                    testModel.eval()\n",
    "                    v_running_loss = 0.0\n",
    "                    for v, data in enumerate(val_loader):\n",
    "                        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                        v_outputs = testModel(inputs)\n",
    "                        v_loss = criterion(v_outputs, labels)\n",
    "                        v_running_loss += v_loss.item()\n",
    "\n",
    "                    print(\"Time: \", datetime.datetime.now().strftime(\"%H:%M:%S\"), \"\\tepoch: \", epoch+1, \"batch: \", i+1, \"Training loss: \", running_loss, \"Validation loss \", v_running_loss)\n",
    "                    validation_losses.append(v_running_loss)\n",
    "                    training_losses.append(running_loss)\n",
    "                    running_loss = 0.0\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "    train_time = end_time - start_time\n",
    "    print(\"Elapsed Training Time: \", datetime.timedelta(seconds = train_time))\n",
    "    print('Finished Training')\n",
    "    \n",
    "    \n",
    "    return running_loss, v_running_loss, epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eba46a-1b06-429e-82dd-2316815270a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 1, 'lr': 0.01, 'batch_size': 2}\n",
      "Train Start. Iteration:  1\n",
      "Training Starting.\n",
      "Time:  20:18:25 \tepoch:  1 batch:  800 Training loss:  30.426110116764903 Validation loss  893.3017697036266\n",
      "Time:  20:19:49 \tepoch:  1 batch:  1600 Training loss:  29.12009604461491 Validation loss  918.0447764396667\n"
     ]
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "#Grid search parameters\n",
    "#dropout=[0.2]\n",
    "batch_size=[2]\n",
    "learn_rate=[0.01]\n",
    "epochs=[1]\n",
    "\n",
    "\n",
    "it=0\n",
    "#for d in dropout:\n",
    "for e in epochs:\n",
    "    for bs in batch_size:\n",
    "        for lr in learn_rate:\n",
    "\n",
    "            it +=1 \n",
    "            #config = {\"d1\": d,\"lr\": lr,\"batch_size\": bs}\n",
    "            config = {\"epochs\": e, \"lr\": lr, \"batch_size\": bs}\n",
    "            #config = {\"lr\": lr,\"batch_size\": bs}\n",
    "\n",
    "            print(config)\n",
    "            print(\"Train Start. Iteration: \",it)\n",
    "            t_loss,v_loss, end_Ep=train_multimodal_model(train_dataset, val_dataset,config)\n",
    "            #t_loss,v_loss, acc, end_Ep=train_model(train_dataset, val_dataset,config)\n",
    "\n",
    "            list_row= str(bs) + \",\" + str(lr) + \",\" + str(t_loss) + \",\" + str(v_loss) + \",\" + str(end_Ep)\n",
    "            #list_row= str(bs) + \",\" + str(lr) + \",\" + str(t_loss) + \",\" + str(v_loss) + \",\" + str(end_Ep), + \",\" + str(acc)\n",
    "\n",
    "            t_list=[list_row]  \n",
    "            result_list.append(t_list)\n",
    "\n",
    "\n",
    "with open('opt_results_multimodal.csv','w') as result_file:\n",
    "    wr = csv.writer(result_file, dialect='excel')\n",
    "    wr.writerow(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cac2c8c-0e6f-418d-80bb-9dddab3d7f28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
